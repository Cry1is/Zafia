{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9cde931a7f234afeafb12e6ce3d386e9",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# ANLI - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\zachary\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch) (4.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_pretrained_bert in c:\\users\\zachary\\anaconda3\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: requests in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (4.64.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (1.21.32)\n",
      "Requirement already satisfied: regex in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (2022.3.15)\n",
      "Requirement already satisfied: numpy in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (1.21.5)\n",
      "Requirement already satisfied: torch>=0.4.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pytorch_pretrained_bert) (2.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.10.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.32 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from boto3->pytorch_pretrained_bert) (1.24.32)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from boto3->pytorch_pretrained_bert) (0.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.32->boto3->pytorch_pretrained_bert) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.32->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.32->boto3->pytorch_pretrained_bert) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from requests->pytorch_pretrained_bert) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from requests->pytorch_pretrained_bert) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from tqdm->pytorch_pretrained_bert) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\zachary\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\zachary\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: responses<0.19 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\zachary\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\zachary\\anaconda3\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipywidgets) (8.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipywidgets) (5.3.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipywidgets) (6.9.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: backcall in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (61.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (302)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.8)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.4.4)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.3)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.2)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: testpath in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.13)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.3.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.4)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\zachary\\anaconda3\\lib\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "a6d7a0ecc59e4219a74a8f4a9c2c437a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11573,
    "execution_start": 1682702772849,
    "scrolled": true,
    "source_hash": "b457949f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load datasets and convert them into dataframes\n",
    "# dataset = load_dataset('anli')\n",
    "# train_r1 = pd.DataFrame(dataset['train_r1'])\n",
    "# dev_r1 = pd.DataFrame(dataset['dev_r1'])\n",
    "# test_r1 = pd.DataFrame(dataset['test_r1'])\n",
    "# train_r2 = pd.DataFrame(dataset['train_r1'])\n",
    "# dev_r2 = pd.DataFrame(dataset['dev_r2'])\n",
    "# test_r2 = pd.DataFrame(dataset['test_r2'])\n",
    "# train_r3 = pd.DataFrame(dataset['train_r3'])\n",
    "# dev_r3 = pd.DataFrame(dataset['dev_r3'])\n",
    "# test_r3 = pd.DataFrame(dataset['test_r3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0995f7f942bb46d993211640a7be90a0",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "ranges": [],
      "toCodePoint": 102,
      "type": "link",
      "url": "https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c"
     }
    ]
   },
   "source": [
    "https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "b1f5db0cb46e4ac79b5ed926ce1dbae6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1682702784486,
    "source_hash": "aa23e097"
   },
   "outputs": [],
   "source": [
    "def convert_to_bert(df):\n",
    "    new_df = {'id': df['uid'], 'label': df['label'], 'text_a': df['premise'], 'text_b': df['hypothesis']}\n",
    "    return pd.DataFrame(data=new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "02e2854c0d9449e0a19a891c0520baee",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 243,
    "execution_start": 1682702784486,
    "source_hash": "5cb1761e"
   },
   "outputs": [],
   "source": [
    "# bert_train_r1 = convert_to_bert(train_r1)\n",
    "# bert_dev_r1 = convert_to_bert(dev_r1)\n",
    "# bert_test_r1 = convert_to_bert(test_r1)\n",
    "\n",
    "# bert_train_r2 = convert_to_bert(train_r2)\n",
    "# bert_dev_r2 = convert_to_bert(dev_r2)\n",
    "# bert_test_r2 = convert_to_bert(test_r2)\n",
    "\n",
    "# bert_train_r3 = convert_to_bert(train_r3)\n",
    "# bert_dev_r3 = convert_to_bert(dev_r3)\n",
    "# bert_test_r3 = convert_to_bert(test_r3)\n",
    "# bert_train_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "f853eea366d64e07a23af6ddfe325140",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1556,
    "execution_start": 1682702785625,
    "source_hash": "4c28bb1d"
   },
   "outputs": [],
   "source": [
    "# bert_train_r1.to_csv('best_train_r1', sep=\"\\t\", header=None, index=False)\n",
    "# bert_dev_r1.to_csv('bert_dev_r1.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_test_r1.to_csv('bert_test_r1.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "# bert_train_r2.to_csv('bert_train_r2.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_dev_r2.to_csv('bert_dev_r2.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_test_r2.to_csv('bert_test_r2.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "# bert_train_r3.to_csv('bert_train_r3.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_dev_r3.to_csv('bert_dev_r3.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_test_r3.to_csv('bert_test_r3.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "53799f69bf0442bdb79e55db264877dc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1693,
    "execution_start": 1682702787187,
    "source_hash": "744b2633"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from tqdm import notebook, trange\n",
    "import os\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tools_class import *\n",
    "import convert_examples_to_features\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "3a2dda8829d04a15b3cfed3f54d4ba01",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1682702788887,
    "source_hash": "d693c4c2"
   },
   "outputs": [],
   "source": [
    "# The input data dir. Should contain the .tsv files (or other data files) for the task.\n",
    "DATA_DIR = \"data/\"\n",
    "\n",
    "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
    "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
    "# bert-base-multilingual-cased, bert-base-chinese.\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "\n",
    "# The name of the task to train.I'm going to name this 'anli'.\n",
    "TASK_NAME = 'anli'\n",
    "\n",
    "# The output directory where the fine-tuned model and checkpoints will be written.\n",
    "OUTPUT_DIR = f'outputs/{TASK_NAME}/'\n",
    "\n",
    "# The directory where the evaluation reports will be written to.\n",
    "REPORTS_DIR = f'reports/{TASK_NAME}_evaluation_report/'\n",
    "\n",
    "# This is where BERT will look for pre-trained models to load parameters from.\n",
    "CACHE_DIR = 'cache/'\n",
    "\n",
    "# The maximum total input sequence length after WordPiece tokenization.\n",
    "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "WARMUP_PROPORTION = 0.1\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "b1b7f8311ed84df4878f88ead3fcab11",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1682702788900,
    "source_hash": "4070f305"
   },
   "outputs": [],
   "source": [
    "output_mode = OUTPUT_MODE\n",
    "\n",
    "cache_dir = CACHE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "31e93b5d0a6b4e189447b469472cfe7f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1682702788911,
    "source_hash": "113d310d"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n",
    "        REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "        os.makedirs(REPORTS_DIR)\n",
    "if not os.path.exists(REPORTS_DIR):\n",
    "    os.makedirs(REPORTS_DIR)\n",
    "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "    os.makedirs(REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "ae5488682f8d44f793fe81d3fc921743",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1682702788916,
    "source_hash": "b9be24b4"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(OUTPUT_DIR) and os.listdir(OUTPUT_DIR):\n",
    "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(OUTPUT_DIR))\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "2b0c651467b3474cb412a45dcca979d2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 384,
    "execution_start": 1682702788926,
    "source_hash": "d4595eda"
   },
   "outputs": [],
   "source": [
    "processor = TernaryClassificationProcessor()\n",
    "train_examples = processor.get_train_examples(DATA_DIR)\n",
    "train_examples_len = len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "70747c396e0e4ee99b88b949226348e9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 33,
    "execution_start": 1682702789300,
    "source_hash": "c74a0197"
   },
   "outputs": [],
   "source": [
    "label_list = processor.get_labels() # [0, 1, 2] for ternary classification\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cell_id": "7ff34e13bc434af58cc65a646f991518",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1682702789313,
    "source_hash": "182044dc"
   },
   "outputs": [],
   "source": [
    "num_train_optimization_steps = int(\n",
    "    train_examples_len / TRAIN_BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS) * NUM_TRAIN_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "42bd5f73c6594bba8b24d1277c2c6eac",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 133,
    "execution_start": 1682702789329,
    "source_hash": "f679bce1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to C:\\Users\\Zachary\\AppData\\Local\\Temp\\tmpwwa4dxpk\n",
      "100%|█████████████████████████████████████████████████████| 231508/231508 [00:00<00:00, 282291.56B/s]\n",
      "INFO:pytorch_pretrained_bert.file_utils:copying C:\\Users\\Zachary\\AppData\\Local\\Temp\\tmpwwa4dxpk to cache at C:\\Users\\Zachary\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for C:\\Users\\Zachary\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:pytorch_pretrained_bert.file_utils:removing temp file C:\\Users\\Zachary\\AppData\\Local\\Temp\\tmpwwa4dxpk\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\Zachary\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "f365d1d2886540f4a72c4ac277fb1ea3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 46,
    "execution_start": 1682702789475,
    "source_hash": "1aa28456"
   },
   "outputs": [],
   "source": [
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "train_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in train_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cell_id": "7e9b46811554453a8f8795ae844f99b9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 664168,
    "execution_start": 1682702789520,
    "source_hash": "da9266cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to convert 16946 examples..\n",
      "Spawning 7 processes..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304a363ed223432d9b97f4085e7d5670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_count = cpu_count() - 1\n",
    "if __name__ ==  '__main__':\n",
    "    print(f'Preparing to convert {train_examples_len} examples..')\n",
    "    print(f'Spawning {process_count} processes..')\n",
    "    with Pool(process_count) as p:\n",
    "        train_features = list(notebook.tqdm(p.imap(convert_examples_to_features.convert_example_to_feature, train_examples_for_processing), total=train_examples_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "cell_id": "ec303612876d4050a8235cf4996e595b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 268,
    "execution_start": 1682703453731,
    "source_hash": "bbcdbd5f"
   },
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"train_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "cbc82e8674324f62ae61a3d688d71f2b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8655,
    "execution_start": 1682703453991,
    "source_hash": "598660f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\Zachary\\AppData\\Local\\Temp\\tmp4ihasrfv\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, cache_dir=CACHE_DIR, num_labels=num_labels)\n",
    "# model = BertForSequenceClassification.from_pretrained(CACHE_DIR + 'cased_base_bert_pytorch.tar.gz', cache_dir=CACHE_DIR, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "6eb2315c9da440148a122f94fbf92266",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 16,
    "execution_start": 1682703462650,
    "source_hash": "2241cfbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "cafc6da5c53147c7a9fbc0f8edfc1763",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 118,
    "execution_start": 1682703462687,
    "source_hash": "6c2ddc85"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": "944d41fcb9c24dd88c44cd28f38b8eba",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 106,
    "execution_start": 1682703462699,
    "source_hash": "86b43b0b"
   },
   "outputs": [],
   "source": [
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=LEARNING_RATE,\n",
    "                     warmup=WARMUP_PROPORTION,\n",
    "                     t_total=num_train_optimization_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "bfd689f62b5740b4a2b6a14ff8c555c7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 58,
    "execution_start": 1682703462748,
    "source_hash": "9df700f0"
   },
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "dae3e794af174cd482a1c47893816931",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 191,
    "execution_start": 1682703462748,
    "source_hash": "12bd8cc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:***** Running training *****\n",
      "INFO:root:  Num examples = 16946\n",
      "INFO:root:  Batch size = 24\n",
      "INFO:root:  Num steps = 706\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", train_examples_len)\n",
    "logger.info(\"  Batch size = %d\", TRAIN_BATCH_SIZE)\n",
    "logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "\n",
    "if OUTPUT_MODE == \"classification\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "caf72cab6cad4507a323387b175f7d15",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1682703462941,
    "source_hash": "e658a15a"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "f50648e460564874bdc7982e4bb4b268",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 817,
    "execution_start": 1682703715194,
    "source_hash": "3f995d19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|                                                                   | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf3273417df401997384ed00a7960bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/707 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████████████████████████████████████████████████| 1/1 [3:32:37<00:00, 12757.46s/it]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(notebook.tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
    "\n",
    "        if OUTPUT_MODE == \"classification\":\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        elif OUTPUT_MODE == \"regression\":\n",
    "            loss_fct = MSELoss()\n",
    "            loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": "2e537dbf48db40a590afe05f61a67aa4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "ec47b7d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outputs/anli/vocab.txt'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "\n",
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(OUTPUT_DIR, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(OUTPUT_DIR, CONFIG_NAME)\n",
    "\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c8bdc978b5174bcca00e43c151fe3c14",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "ranges": [],
      "toCodePoint": 55,
      "type": "link",
      "url": "https://pytorch.org/docs/stable/nn.html#torch.nn.Module"
     }
    ]
   },
   "source": [
    "https://pytorch.org/docs/stable/nn.html#torch.nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b3f75ba4-3f76-4018-a3a7-0b12b965948b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "ranges": [],
      "toCodePoint": 55,
      "type": "link",
      "url": "https://huggingface.co/docs/transformers/model_doc/bert"
     }
    ]
   },
   "source": [
    "https://huggingface.co/docs/transformers/model_doc/bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bf2c1765-6bcd-42de-ac63-376adfae356e",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "ranges": [],
      "toCodePoint": 99,
      "type": "link",
      "url": "https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/model#transformers.PreTrainedModel"
     }
    ]
   },
   "source": [
    "https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/model#transformers.PreTrainedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ef800559-4ff5-4f9a-a563-f7fcfd96a58b' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "5613b4e5218745c38930a12268f80436",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
