{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9cde931a7f234afeafb12e6ce3d386e9",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": []
   },
   "source": [
    "# ANLI - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading torch-2.0.1-cp311-cp311-win_amd64.whl (172.3 MB)\n",
      "     -------------------------------------- 172.3/172.3 MB 3.2 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "     ---------------------------------------- 6.5/6.5 MB 31.8 MB/s eta 0:00:00\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 33.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ------------------------------------- 536.2/536.2 kB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, filelock, torch\n",
      "Successfully installed filelock-3.12.0 mpmath-1.3.0 networkx-3.1 sympy-1.11.1 torch-2.0.1 typing-extensions-4.5.0\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "     -------------------------------------- 123.8/123.8 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=0.4.1 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_pretrained_bert) (2.0.1)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "     --------------------------------------- 14.8/14.8 MB 29.8 MB/s eta 0:00:00\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.26.130-py3-none-any.whl (135 kB)\n",
      "     ---------------------------------------- 135.6/135.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_pretrained_bert) (2.30.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_pretrained_bert) (4.64.1)\n",
      "Requirement already satisfied: regex in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_pretrained_bert) (2022.10.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.2)\n",
      "Collecting botocore<1.30.0,>=1.29.130\n",
      "  Downloading botocore-1.29.130-py3-none-any.whl (10.7 MB)\n",
      "     --------------------------------------- 10.7/10.7 MB 18.7 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "     ---------------------------------------- 79.8/79.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pytorch_pretrained_bert) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pytorch_pretrained_bert) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pytorch_pretrained_bert) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pytorch_pretrained_bert) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->pytorch_pretrained_bert) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from botocore<1.30.0,>=1.29.130->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "     -------------------------------------- 140.9/140.9 kB 8.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\zachary\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.130->boto3->pytorch_pretrained_bert) (1.16.0)\n",
      "Installing collected packages: urllib3, numpy, jmespath, botocore, s3transfer, boto3, pytorch_pretrained_bert\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.2\n",
      "    Uninstalling urllib3-2.0.2:\n",
      "      Successfully uninstalled urllib3-2.0.2\n",
      "Successfully installed boto3-1.26.130 botocore-1.29.130 jmespath-1.0.1 numpy-1.24.3 pytorch_pretrained_bert-0.6.2 s3transfer-0.6.1 urllib3-1.26.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ ----------\n",
      "aiofiles                 22.1.0\n",
      "aiosqlite                0.19.0\n",
      "anyio                    3.6.2\n",
      "argon2-cffi              21.3.0\n",
      "argon2-cffi-bindings     21.2.0\n",
      "arrow                    1.2.3\n",
      "asttokens                2.2.1\n",
      "attrs                    23.1.0\n",
      "Babel                    2.12.1\n",
      "backcall                 0.2.0\n",
      "beautifulsoup4           4.12.2\n",
      "bleach                   6.0.0\n",
      "boto3                    1.26.130\n",
      "botocore                 1.29.130\n",
      "certifi                  2022.12.7\n",
      "cffi                     1.15.1\n",
      "charset-normalizer       3.1.0\n",
      "click                    8.1.3\n",
      "colorama                 0.4.6\n",
      "comm                     0.1.3\n",
      "debugpy                  1.6.7\n",
      "decorator                5.1.1\n",
      "defusedxml               0.7.1\n",
      "executing                1.2.0\n",
      "fastjsonschema           2.16.3\n",
      "filelock                 3.12.0\n",
      "fqdn                     1.5.1\n",
      "idna                     3.4\n",
      "ipykernel                6.22.0\n",
      "ipython                  8.13.2\n",
      "ipython-genutils         0.2.0\n",
      "isoduration              20.11.0\n",
      "jedi                     0.18.2\n",
      "Jinja2                   3.1.2\n",
      "jmespath                 1.0.1\n",
      "joblib                   1.2.0\n",
      "json5                    0.9.11\n",
      "jsonpointer              2.3\n",
      "jsonschema               4.17.3\n",
      "jupyter_client           8.2.0\n",
      "jupyter_core             5.3.0\n",
      "jupyter-events           0.6.3\n",
      "jupyter_server           2.5.0\n",
      "jupyter_server_fileid    0.9.0\n",
      "jupyter_server_terminals 0.4.4\n",
      "jupyter_server_ydoc      0.8.0\n",
      "jupyter-ydoc             0.2.4\n",
      "jupyterlab               3.6.3\n",
      "jupyterlab-pygments      0.2.2\n",
      "jupyterlab_server        2.22.1\n",
      "MarkupSafe               2.1.2\n",
      "matplotlib-inline        0.1.6\n",
      "mistune                  2.0.5\n",
      "mpmath                   1.3.0\n",
      "nbclassic                1.0.0\n",
      "nbclient                 0.7.4\n",
      "nbconvert                7.3.1\n",
      "nbformat                 5.8.0\n",
      "nest-asyncio             1.5.6\n",
      "networkx                 3.1\n",
      "nltk                     3.8.1\n",
      "notebook                 6.5.4\n",
      "notebook_shim            0.2.3\n",
      "numpy                    1.24.3\n",
      "packaging                23.1\n",
      "pandocfilters            1.5.0\n",
      "parso                    0.8.3\n",
      "pickleshare              0.7.5\n",
      "pip                      22.3\n",
      "platformdirs             3.5.0\n",
      "prometheus-client        0.16.0\n",
      "prompt-toolkit           3.0.38\n",
      "psutil                   5.9.5\n",
      "pure-eval                0.2.2\n",
      "pycparser                2.21\n",
      "Pygments                 2.15.1\n",
      "pyrsistent               0.19.3\n",
      "python-dateutil          2.8.2\n",
      "python-json-logger       2.0.7\n",
      "pytorch-pretrained-bert  0.6.2\n",
      "pywin32                  305\n",
      "pywinpty                 2.0.10\n",
      "PyYAML                   6.0\n",
      "pyzmq                    25.0.2\n",
      "regex                    2022.10.31\n",
      "requests                 2.30.0\n",
      "rfc3339-validator        0.1.4\n",
      "rfc3986-validator        0.1.1\n",
      "s3transfer               0.6.1\n",
      "Send2Trash               1.8.2\n",
      "setuptools               65.5.0\n",
      "six                      1.16.0\n",
      "sniffio                  1.3.0\n",
      "soupsieve                2.4.1\n",
      "stack-data               0.6.2\n",
      "sympy                    1.11.1\n",
      "terminado                0.17.1\n",
      "tinycss2                 1.2.1\n",
      "torch                    2.0.1\n",
      "tornado                  6.3.1\n",
      "tqdm                     4.64.1\n",
      "traitlets                5.9.0\n",
      "typing_extensions        4.5.0\n",
      "uri-template             1.2.0\n",
      "urllib3                  1.26.15\n",
      "wcwidth                  0.2.6\n",
      "webcolors                1.13\n",
      "webencodings             0.5.1\n",
      "websocket-client         1.5.1\n",
      "y-py                     0.5.9\n",
      "ypy-websocket            0.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "a6d7a0ecc59e4219a74a8f4a9c2c437a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11573,
    "execution_start": 1682702772849,
    "scrolled": true,
    "source_hash": "b457949f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load datasets and convert them into dataframes\n",
    "# dataset = load_dataset('anli')\n",
    "# train_r1 = pd.DataFrame(dataset['train_r1'])\n",
    "# dev_r1 = pd.DataFrame(dataset['dev_r1'])\n",
    "# test_r1 = pd.DataFrame(dataset['test_r1'])\n",
    "# train_r2 = pd.DataFrame(dataset['train_r1'])\n",
    "# dev_r2 = pd.DataFrame(dataset['dev_r2'])\n",
    "# test_r2 = pd.DataFrame(dataset['test_r2'])\n",
    "# train_r3 = pd.DataFrame(dataset['train_r3'])\n",
    "# dev_r3 = pd.DataFrame(dataset['dev_r3'])\n",
    "# test_r3 = pd.DataFrame(dataset['test_r3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0995f7f942bb46d993211640a7be90a0",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "ranges": [],
      "toCodePoint": 102,
      "type": "link",
      "url": "https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c"
     }
    ]
   },
   "source": [
    "https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b1f5db0cb46e4ac79b5ed926ce1dbae6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1682702784486,
    "source_hash": "aa23e097"
   },
   "outputs": [],
   "source": [
    "def convert_to_bert(df):\n",
    "    new_df = {'id': df['uid'], 'label': df['label'], 'text_a': df['premise'], 'text_b': df['hypothesis']}\n",
    "    return pd.DataFrame(data=new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "02e2854c0d9449e0a19a891c0520baee",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 243,
    "execution_start": 1682702784486,
    "source_hash": "5cb1761e"
   },
   "outputs": [],
   "source": [
    "# bert_train_r1 = convert_to_bert(train_r1)\n",
    "# bert_dev_r1 = convert_to_bert(dev_r1)\n",
    "# bert_test_r1 = convert_to_bert(test_r1)\n",
    "\n",
    "# bert_train_r2 = convert_to_bert(train_r2)\n",
    "# bert_dev_r2 = convert_to_bert(dev_r2)\n",
    "# bert_test_r2 = convert_to_bert(test_r2)\n",
    "\n",
    "# bert_train_r3 = convert_to_bert(train_r3)\n",
    "# bert_dev_r3 = convert_to_bert(dev_r3)\n",
    "# bert_test_r3 = convert_to_bert(test_r3)\n",
    "# bert_train_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a20dcbe26c2742d8a83e98b492e801d8",
    "deepnote_cell_type": "visualization",
    "deepnote_config_collapsed": true,
    "deepnote_to_be_reexecuted": false,
    "deepnote_variable_name": "bert_train_r1",
    "deepnote_visualization_spec": {
     "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
     "config": {
      "customFormatTypes": true
     },
     "encoding": {
      "color": {
       "field": "",
       "format": {
        "decimals": null,
        "type": "default"
       },
       "scale": {
        "type": "linear"
       },
       "sort": null,
       "type": "nominal"
      },
      "x": {
       "field": "",
       "format": {
        "decimals": null,
        "type": "default"
       },
       "scale": {
        "type": "linear"
       },
       "sort": null,
       "type": "nominal"
      },
      "y": {
       "field": "",
       "format": {
        "decimals": null,
        "type": "default"
       },
       "scale": {
        "type": "linear"
       },
       "sort": null,
       "type": "nominal"
      }
     },
     "height": "container",
     "mark": {
      "tooltip": true,
      "type": "bar"
     },
     "width": "container"
    },
    "execution_millis": 915,
    "execution_start": 1682702784784,
    "source_hash": "9764d215"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f853eea366d64e07a23af6ddfe325140",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1556,
    "execution_start": 1682702785625,
    "source_hash": "4c28bb1d"
   },
   "outputs": [],
   "source": [
    "# bert_train_r1.to_csv('best_train_r1', sep=\"\\t\", header=None, index=False)\n",
    "# bert_dev_r1.to_csv('bert_dev_r1.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_test_r1.to_csv('bert_test_r1.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "# bert_train_r2.to_csv('bert_train_r2.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_dev_r2.to_csv('bert_dev_r2.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_test_r2.to_csv('bert_test_r2.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "# bert_train_r3.to_csv('bert_train_r3.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_dev_r3.to_csv('bert_dev_r3.tsv', sep=\"\\t\", header=None, index=False)\n",
    "# bert_test_r3.to_csv('bert_test_r3.tsv', sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "53799f69bf0442bdb79e55db264877dc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1693,
    "execution_start": 1682702787187,
    "source_hash": "744b2633"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from tqdm import tqdm_notebook, trange\n",
    "import os\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tools_class import *\n",
    "import convert_examples_to_features\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "3a2dda8829d04a15b3cfed3f54d4ba01",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1682702788887,
    "source_hash": "d693c4c2"
   },
   "outputs": [],
   "source": [
    "# The input data dir. Should contain the .tsv files (or other data files) for the task.\n",
    "DATA_DIR = \"data/\"\n",
    "\n",
    "# Bert pre-trained model selected in the list: bert-base-uncased, \n",
    "# bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased,\n",
    "# bert-base-multilingual-cased, bert-base-chinese.\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "\n",
    "# The name of the task to train.I'm going to name this 'anli'.\n",
    "TASK_NAME = 'anli'\n",
    "\n",
    "# The output directory where the fine-tuned model and checkpoints will be written.\n",
    "OUTPUT_DIR = f'outputs/{TASK_NAME}/'\n",
    "\n",
    "# The directory where the evaluation reports will be written to.\n",
    "REPORTS_DIR = f'reports/{TASK_NAME}_evaluation_report/'\n",
    "\n",
    "# This is where BERT will look for pre-trained models to load parameters from.\n",
    "CACHE_DIR = 'cache/'\n",
    "\n",
    "# The maximum total input sequence length after WordPiece tokenization.\n",
    "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "\n",
    "TRAIN_BATCH_SIZE = 24\n",
    "EVAL_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1\n",
    "RANDOM_SEED = 42\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "WARMUP_PROPORTION = 0.1\n",
    "OUTPUT_MODE = 'classification'\n",
    "\n",
    "CONFIG_NAME = \"config.json\"\n",
    "WEIGHTS_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b1b7f8311ed84df4878f88ead3fcab11",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1682702788900,
    "source_hash": "4070f305"
   },
   "outputs": [],
   "source": [
    "output_mode = OUTPUT_MODE\n",
    "\n",
    "cache_dir = CACHE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "31e93b5d0a6b4e189447b469472cfe7f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1682702788911,
    "source_hash": "113d310d"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n",
    "        REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "        os.makedirs(REPORTS_DIR)\n",
    "if not os.path.exists(REPORTS_DIR):\n",
    "    os.makedirs(REPORTS_DIR)\n",
    "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
    "    os.makedirs(REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ae5488682f8d44f793fe81d3fc921743",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1682702788916,
    "source_hash": "b9be24b4"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(OUTPUT_DIR) and os.listdir(OUTPUT_DIR):\n",
    "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(OUTPUT_DIR))\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2b0c651467b3474cb412a45dcca979d2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 384,
    "execution_start": 1682702788926,
    "source_hash": "d4595eda"
   },
   "outputs": [],
   "source": [
    "processor = TernaryClassificationProcessor()\n",
    "train_examples = processor.get_train_examples(DATA_DIR)\n",
    "train_examples_len = len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "70747c396e0e4ee99b88b949226348e9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 33,
    "execution_start": 1682702789300,
    "source_hash": "c74a0197"
   },
   "outputs": [],
   "source": [
    "label_list = processor.get_labels() # [0, 1] for binary classification\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7ff34e13bc434af58cc65a646f991518",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1682702789313,
    "source_hash": "182044dc"
   },
   "outputs": [],
   "source": [
    "num_train_optimization_steps = int(\n",
    "    train_examples_len / TRAIN_BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS) * NUM_TRAIN_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "42bd5f73c6594bba8b24d1277c2c6eac",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 133,
    "execution_start": 1682702789329,
    "source_hash": "f679bce1"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f365d1d2886540f4a72c4ac277fb1ea3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 46,
    "execution_start": 1682702789475,
    "source_hash": "1aa28456"
   },
   "outputs": [],
   "source": [
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "train_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in train_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7e9b46811554453a8f8795ae844f99b9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 664168,
    "execution_start": 1682702789520,
    "source_hash": "da9266cc"
   },
   "outputs": [],
   "source": [
    "process_count = cpu_count() - 1\n",
    "if __name__ ==  '__main__':\n",
    "    print(f'Preparing to convert {train_examples_len} examples..')\n",
    "    print(f'Spawning {process_count} processes..')\n",
    "    with Pool(process_count) as p:\n",
    "        train_features = list(tqdm_notebook(p.imap(convert_examples_to_features.convert_example_to_feature, train_examples_for_processing), total=train_examples_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ec303612876d4050a8235cf4996e595b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 268,
    "execution_start": 1682703453731,
    "source_hash": "bbcdbd5f"
   },
   "outputs": [],
   "source": [
    "with open(DATA_DIR + \"train_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cbc82e8674324f62ae61a3d688d71f2b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8655,
    "execution_start": 1682703453991,
    "source_hash": "598660f0"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_MODEL, cache_dir=CACHE_DIR, num_labels=num_labels)\n",
    "# model = BertForSequenceClassification.from_pretrained(CACHE_DIR + 'cased_base_bert_pytorch.tar.gz', cache_dir=CACHE_DIR, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6eb2315c9da440148a122f94fbf92266",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 16,
    "execution_start": 1682703462650,
    "source_hash": "2241cfbb"
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cafc6da5c53147c7a9fbc0f8edfc1763",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 118,
    "execution_start": 1682703462687,
    "source_hash": "6c2ddc85"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "944d41fcb9c24dd88c44cd28f38b8eba",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 106,
    "execution_start": 1682703462699,
    "source_hash": "86b43b0b"
   },
   "outputs": [],
   "source": [
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=LEARNING_RATE,\n",
    "                     warmup=WARMUP_PROPORTION,\n",
    "                     t_total=num_train_optimization_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bfd689f62b5740b4a2b6a14ff8c555c7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 58,
    "execution_start": 1682703462748,
    "source_hash": "9df700f0"
   },
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "nb_tr_steps = 0\n",
    "tr_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "dae3e794af174cd482a1c47893816931",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 191,
    "execution_start": 1682703462748,
    "source_hash": "12bd8cc5"
   },
   "outputs": [],
   "source": [
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", train_examples_len)\n",
    "logger.info(\"  Batch size = %d\", TRAIN_BATCH_SIZE)\n",
    "logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "\n",
    "if OUTPUT_MODE == \"classification\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "elif OUTPUT_MODE == \"regression\":\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "caf72cab6cad4507a323387b175f7d15",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1682703462941,
    "source_hash": "e658a15a"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f50648e460564874bdc7982e4bb4b268",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 817,
    "execution_start": 1682703715194,
    "source_hash": "3f995d19"
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm_notebook(train_dataloader, desc=\"Iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        logits = model(input_ids, segment_ids, input_mask, labels=None)\n",
    "\n",
    "        if OUTPUT_MODE == \"classification\":\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        elif OUTPUT_MODE == \"regression\":\n",
    "            loss_fct = MSELoss()\n",
    "            loss = loss_fct(logits.view(-1), label_ids.view(-1))\n",
    "\n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "        \n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2e537dbf48db40a590afe05f61a67aa4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "ec47b7d9"
   },
   "outputs": [],
   "source": [
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "\n",
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(OUTPUT_DIR, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(OUTPUT_DIR, CONFIG_NAME)\n",
    "\n",
    "torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "tokenizer.save_vocabulary(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c8bdc978b5174bcca00e43c151fe3c14",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "ranges": [],
      "toCodePoint": 55,
      "type": "link",
      "url": "https://pytorch.org/docs/stable/nn.html#torch.nn.Module"
     }
    ]
   },
   "source": [
    "https://pytorch.org/docs/stable/nn.html#torch.nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b3f75ba4-3f76-4018-a3a7-0b12b965948b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "ranges": [],
      "toCodePoint": 55,
      "type": "link",
      "url": "https://huggingface.co/docs/transformers/model_doc/bert"
     }
    ]
   },
   "source": [
    "https://huggingface.co/docs/transformers/model_doc/bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bf2c1765-6bcd-42de-ac63-376adfae356e",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "ranges": [],
      "toCodePoint": 99,
      "type": "link",
      "url": "https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/model#transformers.PreTrainedModel"
     }
    ]
   },
   "source": [
    "https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/model#transformers.PreTrainedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ef800559-4ff5-4f9a-a563-f7fcfd96a58b' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "5613b4e5218745c38930a12268f80436",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
